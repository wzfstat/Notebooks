{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Activation, BatchNormalization, Convolution1D, MaxPooling1D, Convolution2D, MaxPooling2D, Flatten, Dropout, SpatialDropout1D\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.load('X.npy') \n",
    "y = np.load('y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 13, 193)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cust_no = X.shape[0]\n",
    "X_ind = np.array(range(cust_no*13)).reshape(cust_no,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 3000\n",
      "1918 821\n"
     ]
    }
   ],
   "source": [
    "trn_ind, tst_ind = train_test_split(range(cust_no), test_size=0.3, random_state=12)\n",
    "print(len(trn_ind), len(tst_ind))\n",
    "trn_X = X_ind[trn_ind,:]\n",
    "trn_y = y[trn_ind]\n",
    "tst_X = X_ind[tst_ind,:]\n",
    "tst_y = y[tst_ind]\n",
    "print(sum(trn_y), sum(tst_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use \"Embedding Layer\" to train a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/5\n",
      "7000/7000 [==============================] - 23s - loss: 0.5607 - acc: 0.7124 - val_loss: 0.5443 - val_acc: 0.7393\n",
      "Epoch 2/5\n",
      "7000/7000 [==============================] - 23s - loss: 0.5348 - acc: 0.7304 - val_loss: 0.5494 - val_acc: 0.7343\n",
      "Epoch 3/5\n",
      "7000/7000 [==============================] - 23s - loss: 0.5214 - acc: 0.7323 - val_loss: 0.5261 - val_acc: 0.7263\n",
      "Epoch 4/5\n",
      "7000/7000 [==============================] - 24s - loss: 0.5092 - acc: 0.7436 - val_loss: 0.5251 - val_acc: 0.7310\n",
      "Epoch 5/5\n",
      "7000/7000 [==============================] - 22s - loss: 0.5104 - acc: 0.7417 - val_loss: 0.5317 - val_acc: 0.7303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76735576388279436"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(cust_no*13, 193, input_length=13,\n",
    "              weights=[X.reshape(cust_no*13,193)], trainable=False),\n",
    "    SpatialDropout1D(0.2),\n",
    "    Dropout(0.25),\n",
    "    Convolution1D(512, 3, padding='same', activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPooling1D(),\n",
    "    Convolution1D(128, 3, padding='same', activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(1, activation='sigmoid')])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model.fit(trn_X, trn_y, validation_data=(tst_X, tst_y), epochs=5, batch_size=64)#, class_weight={0:1,1:(trn_X.shape[0]-sum(trn_y))/sum(trn_y)})\n",
    "pred = model.predict(tst_X)\n",
    "roc_auc_score(tst_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/5\n",
      "7000/7000 [==============================] - 7s - loss: 0.5063 - acc: 0.7493 - val_loss: 0.4974 - val_acc: 0.7407\n",
      "Epoch 2/5\n",
      "7000/7000 [==============================] - 7s - loss: 0.5024 - acc: 0.7496 - val_loss: 0.4991 - val_acc: 0.7317\n",
      "Epoch 3/5\n",
      "7000/7000 [==============================] - 5s - loss: 0.4959 - acc: 0.7479 - val_loss: 0.4960 - val_acc: 0.7337\n",
      "Epoch 4/5\n",
      "7000/7000 [==============================] - 5s - loss: 0.4959 - acc: 0.7516 - val_loss: 0.4923 - val_acc: 0.7393\n",
      "Epoch 5/5\n",
      "7000/7000 [==============================] - 5s - loss: 0.4889 - acc: 0.7517 - val_loss: 0.4995 - val_acc: 0.7310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76821548174105725"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn_X, trn_y, validation_data=(tst_X, tst_y), epochs=5, batch_size=64)#, class_weight={0:1,1:(trn_X.shape[0]-sum(trn_y))/sum(trn_y)})\n",
    "pred = model.predict(tst_X)\n",
    "roc_auc_score(tst_y, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swap the 2nd and 3rd dim of X and then use Embedding to train a CNN again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 13, 193)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 193, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_swap = np.swapaxes(X,1,2)\n",
    "X_swap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 3000\n",
      "1918 821\n"
     ]
    }
   ],
   "source": [
    "cust_no = X.shape[0]\n",
    "X_ind = np.array(range(cust_no*193)).reshape(cust_no,193)\n",
    "trn_ind, tst_ind = train_test_split(range(cust_no), test_size=0.3, random_state=12)\n",
    "print(len(trn_ind), len(tst_ind))\n",
    "trn_X = X_ind[trn_ind,:]\n",
    "trn_y = y[trn_ind]\n",
    "tst_X = X_ind[tst_ind,:]\n",
    "tst_y = y[tst_ind]\n",
    "print(sum(trn_y), sum(tst_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/5\n",
      "7000/7000 [==============================] - 108s - loss: 0.5724 - acc: 0.7213 - val_loss: 0.5187 - val_acc: 0.7273\n",
      "Epoch 2/5\n",
      "7000/7000 [==============================] - 107s - loss: 0.5358 - acc: 0.7303 - val_loss: 0.4990 - val_acc: 0.7323\n",
      "Epoch 3/5\n",
      "7000/7000 [==============================] - 101s - loss: 0.5279 - acc: 0.7320 - val_loss: 0.5071 - val_acc: 0.7287\n",
      "Epoch 4/5\n",
      "7000/7000 [==============================] - 102s - loss: 0.5258 - acc: 0.7331 - val_loss: 0.5074 - val_acc: 0.7290\n",
      "Epoch 5/5\n",
      "7000/7000 [==============================] - 105s - loss: 0.5190 - acc: 0.7317 - val_loss: 0.5087 - val_acc: 0.7263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76292357734302463"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(cust_no*193, 13, input_length=193,\n",
    "              weights=[X_swap.reshape(cust_no*193,13)], trainable=False),\n",
    "    SpatialDropout1D(0.2),\n",
    "    Dropout(0.25),\n",
    "    Convolution1D(512, 3, padding='same', activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(1, activation='sigmoid')])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model.fit(trn_X, trn_y, validation_data=(tst_X, tst_y), epochs=5, batch_size=64)#, class_weight={0:1,1:(trn_X.shape[0]-sum(trn_y))/sum(trn_y)})\n",
    "pred = model.predict(tst_X)\n",
    "roc_auc_score(tst_y, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use image-like data to train a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_swap[trn_ind].reshape(-1, 1,193, 13)\n",
    "X_test = X_swap[tst_ind].reshape(-1, 1,193, 13)\n",
    "y_train = y[trn_ind]\n",
    "y_test = y[tst_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 1, 193, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(\n",
    "    input_shape=(1, 193, 13),\n",
    "    filters=32,\n",
    "    kernel_size=(1,8),\n",
    "    strides=1,\n",
    "    padding='same',     # Padding method\n",
    "    data_format='channels_first',\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(MaxPooling2D(\n",
    "    pool_size=(1,2),\n",
    "    strides=2,\n",
    "    padding='same',    # Padding method\n",
    "    data_format='channels_first',\n",
    "))\n",
    "\n",
    "\n",
    "model.add(Convolution2D(64, (1,5), strides=1, padding='same', data_format='channels_first'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D((1,2), 2, 'same', data_format='channels_first'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(), 'binary_crossentropy', ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/3\n",
      "7000/7000 [==============================] - 61s - loss: 0.4934 - acc: 0.7546 - val_loss: 0.5106 - val_acc: 0.7367\n",
      "Epoch 2/3\n",
      "7000/7000 [==============================] - 60s - loss: 0.4802 - acc: 0.7619 - val_loss: 0.5172 - val_acc: 0.7307\n",
      "Epoch 3/3\n",
      "7000/7000 [==============================] - 60s - loss: 0.4777 - acc: 0.7627 - val_loss: 0.5203 - val_acc: 0.7303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.74724574459224624"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)\n",
    "pred = model.predict(X_test)\n",
    "roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/1\n",
      "7000/7000 [==============================] - 59s - loss: 0.5059 - acc: 0.7417 - val_loss: 0.5039 - val_acc: 0.7350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75763390888220472"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1, batch_size=64)\n",
    "pred = model.predict(X_test)\n",
    "roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the 3D data to 2D and try xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.79916+0.0072178\ttest-auc:0.72667+0.0149787\n",
      "[50]\ttrain-auc:0.875771+0.00646437\ttest-auc:0.763584+0.0138632\n",
      "[100]\ttrain-auc:0.90521+0.00592872\ttest-auc:0.767762+0.0128771\n",
      "[150]\ttrain-auc:0.922945+0.00584279\ttest-auc:0.76871+0.0126778\n",
      "[200]\ttrain-auc:0.933858+0.00492179\ttest-auc:0.769273+0.0131586\n",
      "[250]\ttrain-auc:0.942243+0.00456055\ttest-auc:0.769229+0.0129019\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eta'] = 0.02\n",
    "param['eval_metric'] = 'auc'\n",
    "param['max_depth'] = 6\n",
    "param['colsample_bytree'] = 0.8\n",
    "param['min_child_weight'] = 10\n",
    "param['base_score'] = np.mean(trn_y)\n",
    "param['silent'] = True\n",
    "param['scale_pos_weight'] = (len(trn_y)-sum(trn_y))/sum(trn_y)\n",
    "# param['max_delta_step'] = 2\n",
    "\n",
    "trn = xgb.DMatrix(trn_X_lr, label=trn_y_lr)\n",
    "res = xgb.cv(param, trn, nfold=4, \n",
    "             stratified=True, num_boost_round=5000, early_stopping_rounds=50,\n",
    "             verbose_eval=50, show_stdv=True, metrics={'auc'}, maximize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.7924\ttest-auc:0.749826\n",
      "[50]\ttrain-auc:0.863402\ttest-auc:0.776185\n",
      "[100]\ttrain-auc:0.89249\ttest-auc:0.779295\n",
      "[150]\ttrain-auc:0.909714\ttest-auc:0.780878\n",
      "[200]\ttrain-auc:0.920018\ttest-auc:0.782301\n"
     ]
    }
   ],
   "source": [
    "min_index = np.argmax(res['test-auc-mean'])\n",
    "tst = xgb.DMatrix(tst_X_lr, label=tst_y_lr)\n",
    "model = xgb.train(param, trn, min_index, [(trn,'train'), (tst, 'test')], verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78309676185983024"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(tst)\n",
    "roc_auc_score(tst_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
