{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing as prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/data/pnc/inbound/clv_lc_201705.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_cleaned = data.loc[:, ['hh_agr_type', 'new_hh_12m', 'rel_tenure', 'age_hh', 'age_grp_4L', 'inc_code_hh', 'inc_grp_3L', \n",
    "                            'consumer_segment', 'psycle_code_ne', 'lifestage', 'dma', 'footprint_clv', 'market_clv',\n",
    "                            'tch_dmail_impr_lag', 'tch_email_impr_lag', 'cim_olb_impr_lag', 'cim_ccc_impr_lag',\n",
    "                            'cim_atm_impr_lag', 'cim_tel_impr_lag', 'cim_pli_impr_lag', 'cim_plo_impr_lag', 'class_modal',\n",
    "                            'dd_hh', 'sv_hh', 'mm_hh', 'cd_hh', 'ir_hh', 'pp_hh', 'cc_hh', 'mt_hh', 'heil_hh', 'heloc_hh', \n",
    "                            'pil_hh', 'ploc_hh', 'auto_hh', 'sl_hh', 'iil_hh', 'sdin_hh', 'dc_flag', 'cc_flag', 'od_late_fee']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197358, 40)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned = data_cleaned.loc[data_cleaned[\"class_modal\"] == 1]\n",
    "data_cleaned = data_cleaned.drop('class_modal', axis=1)\n",
    "data_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_cleaned = data_cleaned.apply(lambda x: x.fillna(x.value_counts().index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_var = ['hh_agr_type', 'age_grp_4L', 'inc_grp_3L', 'consumer_segment', 'lifestage', 'dma', 'market_clv']\n",
    "for x in char_var:\n",
    "    coding = prep.LabelEncoder()\n",
    "    data_cleaned[x] = coding.fit_transform(data_cleaned[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = data_cleaned.loc[:, 'dd_hh':'od_late_fee']\n",
    "features = data_cleaned.loc[:, 'hh_agr_type':'cim_plo_impr_lag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate train and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = np.random.rand(len(features))\n",
    "train = sample <= 0.6\n",
    "valid = ((sample > 0.6) & (sample <= 0.8))\n",
    "test = sample > 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118529, 21)\n",
      "(39300, 21)\n",
      "(39529, 21)\n"
     ]
    }
   ],
   "source": [
    "features_train = features[train].values\n",
    "print(features_train.shape)\n",
    "features_valid = features[valid].values\n",
    "print(features_valid.shape)\n",
    "features_test = features[test].values\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118529, 19)\n",
      "(39300, 19)\n",
      "(39529, 19)\n"
     ]
    }
   ],
   "source": [
    "labels_train = labels[train].values\n",
    "print(labels_train.shape)\n",
    "labels_valid = labels[valid].values\n",
    "print(labels_valid.shape)\n",
    "labels_test = labels[test].values\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive multi-task learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Activation, BatchNormalization, Dropout\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(21,), dtype='float32')\n",
    "input_batchnorm = BatchNormalization(momentum=0.9)(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shared_hidden1 = Dense(100, activation=None)(input_batchnorm)\n",
    "shared_batchnorm1 = BatchNormalization(momentum=0.9)(shared_hidden1)\n",
    "shared_activation1 = Activation('elu')(shared_batchnorm1)\n",
    "shared_dropout1 = Dropout(0.2)(shared_activation1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shared_hidden2 = Dense(50, activation=None)(shared_dropout1)\n",
    "shared_batchnorm2 = BatchNormalization(momentum=0.9)(shared_hidden2)\n",
    "shared_activation2 = Activation('elu')(shared_batchnorm2)\n",
    "shared_dropout2 = Dropout(0.2)(shared_activation2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shared_hidden3 = Dense(21, activation=None)(shared_dropout2)\n",
    "shared_batchnorm3 = BatchNormalization(momentum=0.9)(shared_hidden3)\n",
    "shared_activation3 = Activation('elu')(shared_batchnorm3)\n",
    "shared_dropout3 = Dropout(0.2)(shared_activation3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "separated_hidden1 = [Dense(100, activation=None)(shared_dropout3) for k in range(19)]\n",
    "separated_batchnorm1 = [BatchNormalization(momentum=0.9)(separated_hidden1[k]) for k in range(19)]\n",
    "separated_activation1 = [Activation('elu')(separated_batchnorm1[k]) for k in range(19)]\n",
    "separated_dropout1 = [Dropout(0.2)(separated_activation1[k]) for k in range(19)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "separated_hidden2 = [Dense(50, activation=None)(separated_dropout1[k]) for k in range(19)]\n",
    "separated_batchnorm2 = [BatchNormalization(momentum=0.9)(separated_hidden2[k]) for k in range(19)]\n",
    "separated_activation2 = [Activation('elu')(separated_batchnorm2[k]) for k in range(19)]\n",
    "separated_dropout2 = [Dropout(0.2)(separated_activation2[k]) for k in range(19)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = [Dense(1, activation=None)(separated_dropout2[k]) for k in range(19)]\n",
    "output_batchnorm = [BatchNormalization(momentum=0.9)(outputs[k]) for k in range(19)]\n",
    "output_activation = [Activation('softmax')(output_batchnorm[k]) for k in range(19)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(features_train, [labels_train[:,k] for k in range(19)], batch_size=1000, epochs=30, \n",
    "          validation_data=(features_valid, [labels_valid[:,k] for k in range(19)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.evaluate(features_test, [labels_test[:,k] for k in range(19)], batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.float64, shape=[None, 21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden1 = tf.contrib.layers.fully_connected(inputs, 52, activation_fn=None)\n",
    "norm1 = tf.contrib.layers.batch_norm(hidden1, center=True, scale=True)\n",
    "out1 = tf.nn.relu(norm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden2 = tf.contrib.layers.fully_connected(out1, 10, activation_fn=None)\n",
    "norm2 = tf.contrib.layers.batch_norm(hidden2, center=True, scale=True)\n",
    "out2 = tf.nn.relu(norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = [tf.contrib.layers.fully_connected(out2, 1) for i in range(19)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [tf.placeholder(tf.float64, shape=[None, 1]) for i in range(19)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "losses = [tf.nn.softmax_cross_entropy_with_logits(logits=outputs[i], labels=labels[i]) for i in range(19)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joint_loss = sum(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizers = [tf.train.AdamOptimizer(0.01).minimize(losses[i]) for i in range(19)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joint_optimizer = tf.train.AdamOptimizer(0.01).minimize(joint_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
