{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data preprocessing for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract \"# of weeks\" for each customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reader = pd.read_csv('../../data/pnc/inbound/sample_1_not_offered_data.csv', chunksize=100000)\n",
    "# data = None\n",
    "# keys_all = set()\n",
    "# for chunk in reader:\n",
    "#     items = pd.groupby(chunk, by='cif_permanent_key').count()['week'].reset_index()\n",
    "#     if items.loc[0,'cif_permanent_key'] in keys_all:\n",
    "#         items.loc[0,'week'] += data.week.iloc[-1]\n",
    "#         data = data[:-1]\n",
    "#     keys_all |= set(items['cif_permanent_key'])\n",
    "#     data = pd.concat([data, items])\n",
    "    \n",
    "# data_cross = pd.read_csv('cross_data.csv')\n",
    "# data_comb = pd.merge(data, data_cross.loc[:,['cif_permanent_key', 'apply']], on='cif_permanent_key')\n",
    "# data_comb.to_csv('data_count.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_cross = pd.read_csv('cross_data.csv')\n",
    "data_count = pd.read_csv('data_count.csv')\n",
    "data_sample = pd.read_csv('../../../data/pnc/inbound/sample_1_not_offered_data.csv', nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_key = list(data_count.cif_permanent_key[data_count.eval('week >= 52 and apply == 1')])\n",
    "neg_key = list(data_count.cif_permanent_key[data_count.eval('week >= 52 and apply == 0')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use all eligible positive customers and randomly select negative customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2739, 7261, 10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 10000\n",
    "np.random.seed(1234)\n",
    "sel_neg_key = list(np.random.choice(neg_key, total-len(pos_key), replace=False))\n",
    "sel_key = pos_key + sel_neg_key\n",
    "len(pos_key), len(sel_neg_key), len(pos_key)+len(sel_neg_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the first 52 weeks' data for the chosen customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reader = pd.read_csv('../../data/pnc/inbound/sample_1_not_offered_data.csv', chunksize=100000)\n",
    "# data = None\n",
    "# keys_all = set()\n",
    "# for chuck in reader:\n",
    "#     items = chuck[[key in sel_key and week <=52 for key, week in zip(chuck.cif_permanent_key, chuck.week)]]\n",
    "#     try:\n",
    "#         data = pd.concat([data, items])\n",
    "#     except:\n",
    "#         data = items\n",
    "#     del items\n",
    "# data.to_csv('data_52w.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_52w.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_count = pd.read_csv('data_count.csv')\n",
    "key_ind = [k in sel_key for k in data_count.cif_permanent_key]\n",
    "y = data_count.loc[key_ind,'apply'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py:2834: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  **kwargs)\n"
     ]
    }
   ],
   "source": [
    "categorical_var = ['age_grp_4L', 'hh_agr_type', 'inc_grp_3L', 'lifestage', 'segment']\n",
    "date_var = ['date', 'time_period', 'date_applied', 'week', 'week_applied', 'MLK', 'Presidents', 'Memorial', \n",
    "            'Independence', 'Labor', 'Colombus', 'Veterans', 'Thanksgiving', 'Christmas', 'NewYears']\n",
    "key_var = ['rlb_location_key']\n",
    "others = ['offered']\n",
    "groupby = ['cif_permanent_key', 'month', 'year', 'apply']\n",
    "\n",
    "data = pd.get_dummies(data, columns=categorical_var, prefix_sep=['_' for col in categorical_var])\n",
    "features_std = list(data.columns)\n",
    "for f in date_var + key_var + others + groupby:\n",
    "    features_std.remove(f)\n",
    "    \n",
    "X = data[features_std] \n",
    "X.rename(columns={'segment_Lower Mas':'segment_Lower', 'segment_Mass Affl':'segment_Mass', 'segment_Upper Mas':'segment_Upper',\n",
    "                  'age_grp_4L_a [18 - 25]':'age_grp_4L_a', 'age_grp_4L_b [26 - 45]':'age_grp_4L_b', 'age_grp_4L_c [46 - 65]':'age_grp_4L_c',\n",
    "                  'age_grp_4L_d [66 - 100]':'age_grp_4L_d', 'inc_grp_3L_a [0 - 50k)':'inc_grp_3L_a', 'inc_grp_3L_b [50k - 125k)':'inc_grp_3L_b',\n",
    "                  'inc_grp_3L_c [125k - inf)':'inc_grp_3L_c'}, inplace=True)\n",
    "    \n",
    "features = X.columns\n",
    "std_scale = StandardScaler().fit(X)\n",
    "X_std = std_scale.transform(X)\n",
    "X_std_all = pd.concat([pd.DataFrame(X_std, columns=features), data[groupby]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape to 3D data (customers x months x features = 10000 x 13 x 193)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = list(X_std_all.columns)\n",
    "month_str = pd.Series([i.zfill(2) for i in list(X_std_all.month.apply(str))])\n",
    "X_std_all['ym'] = X_std_all.year.apply(str) + '+' + month_str\n",
    "\n",
    "features.remove('month')\n",
    "features.remove('year')\n",
    "features.remove('apply')\n",
    "try: \n",
    "    features.remove('ym')\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group = pd.groupby(X_std_all, by=['cif_permanent_key','ym']).apply(np.max)\n",
    "group_mouth = pd.DataFrame(group[features].as_matrix(), columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a3d = group_month.groupby('cif_permanent_key').apply(pd.DataFrame.as_matrix).apply(lambda x: x[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.stack(a3d)\n",
    "cust_no = X.shape[0]\n",
    "\n",
    "X_ind = np.array(range(cust_no*13)).reshape(cust_no,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('X.npy', X) \n",
    "np.save('y.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1918 821\n"
     ]
    }
   ],
   "source": [
    "trn_X, tst_X, trn_y, tst_y = train_test_split(X, y, test_size=0.3, random_state=12)\n",
    "print(sum(trn_y), sum(tst_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
